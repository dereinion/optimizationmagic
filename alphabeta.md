Check for optimal h:
https://en.wikipedia.org/wiki/Numerical_differentiation

Gradienty stuffy:
https://math.stackexchange.com/questions/221968/why-must-the-gradient-vector-always-be-directed-in-an-increasing-direction


Gradient:
http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%81%D0%BF%D1%83%D1%81%D0%BA%D0%B0

Test da shit out:
https://en.wikipedia.org/wiki/Test_functions_for_optimization

Bartish's calling':
https://ami.lnu.edu.ua/wp-content/uploads/2014/02/DO_4.pdf


https://towardsdatascience.com/why-visualize-gradient-descent-optimization-algorithms-a393806eee2

https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c


https://www.youtube.com/watch?v=IHZwWFHWa-w

https://www.youtube.com/watch?v=tIpKfDc295M

https://www.youtube.com/watch?v=GkB4vW16QHI

https://www.youtube.com/watch?v=QQPz3eXXgQI




